{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d41915c",
      "metadata": {
        "id": "9d41915c"
      },
      "source": [
        "## 1주차 - 기초선형대수 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607e69d9",
      "metadata": {
        "id": "607e69d9"
      },
      "source": [
        "안녕하세요 투빅스 여러분 24기 이상민입니다.   \n",
        "1주차 정규세션 다들 고생하셨습니다.   \n",
        "모두에게 유익한 시간이었기를 바랍니다.   \n",
        "선형대수내용과 관련하여 간단한 과제들을 출제했습니다.   \n",
        "첫 주차이기에 간단한 내용들로만 구성해보았으니 문제를 잘 읽어보시고 과제 수행해주시기바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b98b0c",
      "metadata": {
        "id": "15b98b0c"
      },
      "source": [
        "### Q1. 이론문제(서술형)\n",
        "#### 우리는 신경망이 단순히 선형변환(행렬 곱)만으로 이루어지지 않고, 중간에 비선형 함수(Non-linear function)가 반드시 필요하다는 것을 배웠습니다.\n",
        "\n",
        "##### 1-1. 선형변환을 여러 번 겹쳐서 수행했을 때 여전히 '선형적'인 성질이 유지된다는 것이 어떤 의미인지 설명하고,\n",
        "\n",
        "##### 1-2. 이를 통해 딥러닝 모델에서 활성화 함수(Activation Function)와 같은 비선형성이 왜 필수적인지 서술하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0b3d12",
      "metadata": {
        "id": "4e0b3d12"
      },
      "source": [
        "---\n",
        "**정답 입력**\n",
        "\n",
        "1-1 : 선형변환을 아무리 많이 쌓아도, 결과는 여전히 하나의 선형변환이라는 의미이다.\n",
        "\n",
        "`W2​(W1​x+b1​)+b2​=(W2​W1​)x+(W2​b1​+b2​)`\n",
        "\n",
        "1-2 : 선형변환은 결국 직선을 직선으로 변화시키는 것이기에, 데이터를 바라보는 각도와 차원을 바꿀 순 있어도 공간을 왜곡시키는 것은 불가능하기 때문이다. XOR문제와 같은 비선형 문제를 풀기 위해선 입력 공간이 접히고, 구부러지고, 분리되는 과정이 필요한데, 이는 선형변환 + 비선형함수의 반복 합성을 통해 가능해진다.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5daedf55",
      "metadata": {
        "id": "5daedf55"
      },
      "source": [
        "### Q2. 개념 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc15efb5",
      "metadata": {
        "id": "fc15efb5"
      },
      "source": [
        "#### 2-1. **[내적(Dot Product)과 Norm]**   \n",
        "##### 두 벡터의 유사도를 판단하거나 길이를 구할 때 사용되는 함수입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_similarity_components(v1, v2):\n",
        "    \"\"\"\n",
        "    v1, v2: numpy array (1D vectors)\n",
        "    반환값: 두 벡터의 내적 값, v1의 norm, v2의 norm\n",
        "    \"\"\"\n",
        "    # 1. 두 벡터의 내적(Dot Product)을 계산\n",
        "    dot_prod = np.dot(v1, v2)\n",
        "\n",
        "    # 2. 각 벡터의 크기(Norm, L2 Norm)를 계산\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "\n",
        "    return dot_prod, norm_v1, norm_v2\n"
      ],
      "metadata": {
        "id": "TDS-nfVELNma"
      },
      "id": "TDS-nfVELNma",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9ac9c2ab",
      "metadata": {
        "id": "9ac9c2ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0756a47-6632-4397-d5e3-9e25fca82a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "내적값 : 56.0, v1의 norm : 5.0, v2의 norm : 13.0\n"
          ]
        }
      ],
      "source": [
        "# 함수 확인\n",
        "v1 = np.array([3.0, 4.0])  # 예시 벡터 1\n",
        "v2 = np.array([12.0, 5.0])  # 예시 벡터 2\n",
        "out = calculate_similarity_components(v1, v2)\n",
        "\n",
        "print(f\"내적값 : {out[0]}, v1의 norm : {out[1]}, v2의 norm : {out[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf443749",
      "metadata": {
        "id": "cf443749"
      },
      "source": [
        "#### 2-2. **[선형변환 (행렬 곱)]**\n",
        "##### 입력 벡터를 다른 차원의 공간으로 매핑하는 선형변환 과정입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_transformation(x, W, b):\n",
        "    \"\"\"\n",
        "    x: 입력 벡터 (input features)\n",
        "    W: 가중치 행렬 (weight matrix)\n",
        "    b: 편향 벡터 (bias)\n",
        "    반환값: 선형변환 결과 z = Wx + b\n",
        "    \"\"\"\n",
        "    # 1. 행렬 곱 Wx 수행\n",
        "    wx = W @ x\n",
        "\n",
        "    # 2. 편향(bias) 더하기\n",
        "    z = wx + b\n",
        "\n",
        "    return z\n"
      ],
      "metadata": {
        "id": "M_Jo3C3YLM8T"
      },
      "id": "M_Jo3C3YLM8T",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "01b29ac6",
      "metadata": {
        "id": "01b29ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a16ac75-d0da-4d2c-fe9c-3c3d1914a9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.6 0.3]\n"
          ]
        }
      ],
      "source": [
        "# 함수 확인\n",
        "x = np.array([1.0, 2.0])  # 예시 input vector\n",
        "W = np.array([[0.5, 1.0], [1.5, -0.5]])  # 예시 weight matrix\n",
        "b = np.array([0.1, -0.2])  # 예시 bias vector\n",
        "\n",
        "print(linear_transformation(x, W, b))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1125f25d",
      "metadata": {
        "id": "1125f25d"
      },
      "source": [
        "#### 2-3. **[비선형성 (ReLU 함수)]**\n",
        "##### 선형변환 결과에 비선형성을 부여하는 활성화 함수입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad0e5215",
      "metadata": {
        "id": "ad0e5215"
      },
      "source": [
        "![ReLU](https://velog.velcdn.com/images/sasganamabeer/post/4ea7fb74-2c3a-423f-8e47-bde64cddebb2/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%2C%202021-05-13%2015-27-54.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8cc17868",
      "metadata": {
        "id": "8cc17868"
      },
      "outputs": [],
      "source": [
        "def relu_function(z):\n",
        "    \"\"\"\n",
        "    z: 선형변환을 거친 값\n",
        "    반환값: 0보다 작으면 0, 0보다 크면 그대로 반환 (max(0, z))\n",
        "    \"\"\"\n",
        "    # numpy의 maximum 함수 등을 사용하여 ReLU를 구현하세요.\n",
        "    a = np.maximum(0, z)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "176c1447",
      "metadata": {
        "id": "176c1447"
      },
      "source": [
        "### Q3. 응용 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1508a9",
      "metadata": {
        "id": "6a1508a9"
      },
      "source": [
        "위 2번 문제에서 작성한 힘수들(calculate_similarity_components, linear_transformation, relu_function)을 활용하여 아래 문제를 해결하는 코드를 작성하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1474f9b",
      "metadata": {
        "id": "f1474f9b"
      },
      "source": [
        "#### 간단한 유사도 기반 분류기 구현.\n",
        "입력 데이터 x가 주어졌을 때, 1차적으로 선형 변환과 비선형 변환을 거쳐 특징(feature)을 추출하고, 이 추출된 특징이 기준 벡터(reference vector)와 얼마나 유사한지 코사인 유사도(Cosine Similarity)로 판단합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6b4d9ed7",
      "metadata": {
        "id": "6b4d9ed7"
      },
      "outputs": [],
      "source": [
        "def forward_and_evaluate(x, W, b, ref_vector):\n",
        "\n",
        "    # 1. 선형 변환\n",
        "    z = linear_transformation(x, W, b)\n",
        "\n",
        "    # 2. 비선형 활성화\n",
        "    feature = relu_function(z)\n",
        "\n",
        "    # 3. 코사인 유사도 계산\n",
        "    dot_prod, norm_f, norm_ref = calculate_similarity_components(feature, ref_vector)\n",
        "\n",
        "    # 코사인 유사도 공식 적용 (분모가 0이 아님을 가정)\n",
        "    cosine_sim = dot_prod / (norm_f * norm_ref)\n",
        "\n",
        "    return cosine_sim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c04901de",
      "metadata": {
        "id": "c04901de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfef4ce1-6043-4445-90ed-62cd34864f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6708203932499369\n"
          ]
        }
      ],
      "source": [
        "# 테스트 코드\n",
        "x = np.array([1, 2])\n",
        "W = np.array([[1, -1], [2, 0], [0, 1]]) # 3x2 행렬\n",
        "b = np.array([0, 1, -1])\n",
        "ref = np.array([1, 1, 0])\n",
        "print(forward_and_evaluate(x, W, b, ref))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d09e9a",
      "metadata": {
        "id": "f4d09e9a"
      },
      "source": [
        "+자유롭게 다른 활성화함수를 정의하는 등을 통해 추가적으로 학습하셔도 좋을것 같습니다.\n",
        "\n",
        "고생하셨습니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d2d1b1",
      "metadata": {
        "id": "18d2d1b1"
      },
      "source": [
        "### **과제 완료 후 잊지말고 꼭 깃허브에 제출해주시기바랍니다.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}