{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQp8_ciLdB8R",
        "outputId": "78736757-2587-4bc0-cc52-83b459c458e0"
      },
      "id": "fQp8_ciLdB8R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d41915c",
      "metadata": {
        "id": "9d41915c"
      },
      "source": [
        "## 1주차 - 기초선형대수 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607e69d9",
      "metadata": {
        "id": "607e69d9"
      },
      "source": [
        "안녕하세요 투빅스 여러분 24기 이상민입니다.   \n",
        "1주차 정규세션 다들 고생하셨습니다.   \n",
        "모두에게 유익한 시간이었기를 바랍니다.   \n",
        "선형대수내용과 관련하여 간단한 과제들을 출제했습니다.   \n",
        "첫 주차이기에 간단한 내용들로만 구성해보았으니 문제를 잘 읽어보시고 과제 수행해주시기바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b98b0c",
      "metadata": {
        "id": "15b98b0c"
      },
      "source": [
        "### Q1. 이론문제(서술형)\n",
        "#### 우리는 신경망이 단순히 선형변환(행렬 곱)만으로 이루어지지 않고, 중간에 비선형 함수(Non-linear function)가 반드시 필요하다는 것을 배웠습니다.\n",
        "\n",
        "##### 1-1. 선형변환을 여러 번 겹쳐서 수행했을 때 여전히 '선형적'인 성질이 유지된다는 것이 어떤 의미인지 설명하고,\n",
        "\n",
        "##### 1-2. 이를 통해 딥러닝 모델에서 활성화 함수(Activation Function)와 같은 비선형성이 왜 필수적인지 서술하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0b3d12",
      "metadata": {
        "id": "4e0b3d12"
      },
      "source": [
        "---\n",
        "**정답 입력**\n",
        "\n",
        "1-1 : 선형변환을 여러 번 겹쳐서 수행하더라도, 그 결과는 하나의 선형변환으로 표현될 수 있으므로 전체 변환은 여전히 선형적임을 의미한다. 예를 들어, 아래와 같은 신경망 구조를 생각해보면,  \n",
        "\n",
        "<a href='https://postimages.org/' target='_blank'><img src='https://i.postimg.cc/QCW7dQSW/seonhyeong-singyeongmang-imiji.png' border='0' alt='seonhyeong-singyeongmang-imiji'></a>\n",
        "\n",
        "입력 $x_1, x_2$ 는 각각 가중치를 통해 중간층 $y_1, y_2$ 로 선형 변환되고, 이후 다시 가중치 1을 통해 출력 z로 선형 변환된다.\n",
        "\n",
        "이 과정에서 각 층은 모두 가중치 곱셈과 상수항 덧셈으로 이루어진 선형 변환임을 알 수 있다.\n",
        "\n",
        "따라서 최종 식은,   \n",
        "$z = y_1+y_2 = 2x_1+1 + 3x_2-1 = 2x_1+3x_2$\n",
        "\n",
        "와 같이 하나의 선형식으로 정리될 수 있다.\n",
        "즉 여러 번의 선형 변환을 연속적으로 적용하더라도, 그 합성 결과는 여전히 선형 변환이라는 점에서 선형성이 유지된다고 볼 수 있다.   \n",
        "<br></br>\n",
        "1-2 : 이를 통해 비선형성을 추가해주지 않는다면 곱하고 더하는 계산만 반복되기 때문에, 신경망이 깊어진다하더라도 표현력이 제한된다. 따라서 활성화 함수와 같은 비선형성을 도입함으로써 복잡한 이미지 특징을 학습할 수 있다.   \n",
        "아래와 같은 사진에서 이를 확인할 수 있다.  \n",
        "\n",
        "<a href='https://postimages.org/' target='_blank'><img src='https://i.postimg.cc/ZRXGNmPp/image.png' border='0' alt='image'></a><br><a href='https://postimages.org/ko/'></a><br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5daedf55",
      "metadata": {
        "id": "5daedf55"
      },
      "source": [
        "### Q2. 개념 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc15efb5",
      "metadata": {
        "id": "fc15efb5"
      },
      "source": [
        "#### 2-1. **[내적(Dot Product)과 Norm]**   \n",
        "##### 두 벡터의 유사도를 판단하거나 길이를 구할 때 사용되는 함수입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f34a19fb",
      "metadata": {
        "id": "f34a19fb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_similarity_components(v1, v2):\n",
        "    \"\"\"\n",
        "    v1, v2: numpy array (1D vectors)\n",
        "    반환값: 두 벡터의 내적 값, v1의 norm, v2의 norm\n",
        "    \"\"\"\n",
        "    # 1. 두 벡터의 내적(Dot Product)을 계산하세요.\n",
        "    dot_prod = np.dot(v1, v2)\n",
        "\n",
        "    # 2. 각 벡터의 크기(Norm, L2 Norm)를 계산하세요.\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "\n",
        "    return dot_prod, norm_v1, norm_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ac9c2ab",
      "metadata": {
        "id": "9ac9c2ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a297a8-f7f1-4237-e0c9-03cd7e01ac40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "내적값 : 56.0, v1의 norm : 5.0, v2의 norm : 13.0\n"
          ]
        }
      ],
      "source": [
        "# 함수 확인\n",
        "v1 = np.array([3.0, 4.0])  # 예시 벡터 1\n",
        "v2 = np.array([12.0, 5.0])  # 예시 벡터 2\n",
        "out = calculate_similarity_components(v1, v2)\n",
        "\n",
        "print(f\"내적값 : {out[0]}, v1의 norm : {out[1]}, v2의 norm : {out[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf443749",
      "metadata": {
        "id": "cf443749"
      },
      "source": [
        "#### 2-2. **[선형변환 (행렬 곱)]**\n",
        "##### 입력 벡터를 다른 차원의 공간으로 매핑하는 선형변환 과정입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a7e127e",
      "metadata": {
        "id": "5a7e127e"
      },
      "outputs": [],
      "source": [
        "def linear_transformation(x, W, b):\n",
        "    \"\"\"\n",
        "    x: 입력 벡터 (input features)\n",
        "    W: 가중치 행렬 (weight matrix)\n",
        "    b: 편향 벡터 (bias)\n",
        "    반환값: 선형변환 결과 z = Wx + b\n",
        "    \"\"\"\n",
        "    # 1. 행렬 곱(Matrix Multiplication) Wx를 수행하세요.\n",
        "    # 힌트: numpy의 행렬 곱 연산자(@) 또는 np.dot, np.matmul 사용\n",
        "    wx = np.matmul(W, x)\n",
        "    # 2. 편향(bias)을 더하세요.\n",
        "    z = wx + b\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b29ac6",
      "metadata": {
        "id": "01b29ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81feeb6b-4167-495b-8d75-287c5207c60d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.6 0.3]\n"
          ]
        }
      ],
      "source": [
        "# 함수 확인\n",
        "x = np.array([1.0, 2.0])  # 예시 input vector\n",
        "W = np.array([[0.5, 1.0], [1.5, -0.5]])  # 예시 weight matrix\n",
        "b = np.array([0.1, -0.2])  # 예시 bias vector\n",
        "\n",
        "print(linear_transformation(x, W, b))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1125f25d",
      "metadata": {
        "id": "1125f25d"
      },
      "source": [
        "#### 2-3. **[비선형성 (ReLU 함수)]**\n",
        "##### 선형변환 결과에 비선형성을 부여하는 활성화 함수입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad0e5215",
      "metadata": {
        "id": "ad0e5215"
      },
      "source": [
        "![ReLU](https://velog.velcdn.com/images/sasganamabeer/post/4ea7fb74-2c3a-423f-8e47-bde64cddebb2/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%2C%202021-05-13%2015-27-54.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc17868",
      "metadata": {
        "id": "8cc17868"
      },
      "outputs": [],
      "source": [
        "def relu_function(z):\n",
        "    \"\"\"\n",
        "    z: 선형변환을 거친 값\n",
        "    반환값: 0보다 작으면 0, 0보다 크면 그대로 반환 (max(0, z))\n",
        "    \"\"\"\n",
        "    # numpy의 maximum 함수 등을 사용하여 ReLU를 구현하세요.\n",
        "    a = np.maximum(0, z)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "176c1447",
      "metadata": {
        "id": "176c1447"
      },
      "source": [
        "### Q3. 응용 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1508a9",
      "metadata": {
        "id": "6a1508a9"
      },
      "source": [
        "위 2번 문제에서 작성한 힘수들(calculate_similarity_components, linear_transformation, relu_function)을 활용하여 아래 문제를 해결하는 코드를 작성하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1474f9b",
      "metadata": {
        "id": "f1474f9b"
      },
      "source": [
        "#### 간단한 유사도 기반 분류기 구현.\n",
        "입력 데이터 x가 주어졌을 때, 1차적으로 선형 변환과 비선형 변환을 거쳐 특징(feature)을 추출하고, 이 추출된 특징이 기준 벡터(reference vector)와 얼마나 유사한지 코사인 유사도(Cosine Similarity)로 판단합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4d9ed7",
      "metadata": {
        "id": "6b4d9ed7"
      },
      "outputs": [],
      "source": [
        "def forward_and_evaluate(x, W, b, ref_vector):\n",
        "\n",
        "    # 1. 선형 변환\n",
        "    y = linear_transformation(x, W, b)\n",
        "\n",
        "    # 2. 비선형 활성화\n",
        "    z = relu_function(y)\n",
        "\n",
        "    # 3. 코사인 유사도 계산\n",
        "    out = calculate_similarity_components(z, ref_vector)\n",
        "\n",
        "    # 코사인 유사도 공식 적용 (분모가 0이 아님을 가정)\n",
        "    print('### 결과 확인 ###')\n",
        "    print('내적값:', out[0])\n",
        "    print('z_norm:', out[1])\n",
        "    print('ref_vector_norm:', out[2])\n",
        "    print('\\n### cosine similarity ###')\n",
        "    similarity = out[0] / (out[1] * out[2])\n",
        "\n",
        "    return  similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04901de",
      "metadata": {
        "id": "c04901de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d9b85a-339d-4bc8-8434-bd4a8c1e7023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 결과 확인 ###\n",
            "내적값: 3\n",
            "z_norm: 3.1622776601683795\n",
            "ref_vector_norm: 1.4142135623730951\n",
            "\n",
            "### cosine similarity ###\n",
            "0.6708203932499369\n"
          ]
        }
      ],
      "source": [
        "# 테스트 코드\n",
        "x = np.array([1, 2])\n",
        "W = np.array([[1, -1], [2, 0], [0, 1]]) # 3x2 행렬\n",
        "b = np.array([0, 1, -1])\n",
        "ref = np.array([1, 1, 0])\n",
        "print(forward_and_evaluate(x, W, b, ref))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코사인 유사도는 일반적으로 0.8 이상이면 매우 유사하다고 판단하므로, 해당 결과는 완전히 유사하다고 하긴 어렵지만, 기준 벡터와 어느정도 연관성이 있다고 볼 수 있다."
      ],
      "metadata": {
        "id": "D6K6nOJ_p2k-"
      },
      "id": "D6K6nOJ_p2k-"
    },
    {
      "cell_type": "markdown",
      "id": "f4d09e9a",
      "metadata": {
        "id": "f4d09e9a"
      },
      "source": [
        "+자유롭게 다른 활성화함수를 정의하는 등을 통해 추가적으로 학습하셔도 좋을것 같습니다.\n",
        "\n",
        "고생하셨습니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d2d1b1",
      "metadata": {
        "id": "18d2d1b1"
      },
      "source": [
        "### **과제 완료 후 잊지말고 꼭 깃허브에 제출해주시기바랍니다.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}